library(dataRetrieval)
library(tidyverse)
start=as.Date("1987-10-01")
end= as.Date("2017-09-30")
USGSsites= c("13185000", "13186000", "13190500", "13192200","13200000","13202000")
siteInfo<-readNWISdata(sites= USGSsites, service="site")
### Data Organized by Individual Sites
pCode <- "00060"
Boise_twnSpr <- readNWISuv(siteNumbers = 13185000, parameterCd = pCode, startDate = start, endDate = end) %>% renameNWISColumns() %>% data.frame
SF_featherville <- readNWISuv(siteNumbers = 13186000, parameterCd = pCode, startDate = start, endDate = end) %>% renameNWISColumns() %>% data.frame
Mores<- readNWISuv(siteNumbers=13200000, parameterCd = pCode, startDate = start, endDate = end) %>% renameNWISColumns() %>% data.frame
SF_And<- readNWISuv(siteNumbers = 13190500, parameterCd = pCode, startDate = start, endDate = end) %>% renameNWISColumns() %>% data.frame
SF_Arrow<- readNWISuv(siteNumbers = 13192200, parameterCd = pCode, startDate = start, endDate = end) %>% renameNWISColumns() %>% data.frame
#Missing Data
for ( i in 1:length(SF_Arrow)){
if (SF_Arrow$Flow_Inst[i] == -999999){SF_Arrow$Flow_Inst[i] = NA}
}
for ( i in 1:length(SF_featherville)){
if (SF_featherville$Flow_Inst[i] == -999999){SF_featherville$Flow_Inst[i] = NA}
}
# Merge and subset dataframes
Q1<-list(Boise_twnSpr, SF_featherville, Mores, SF_And, SF_Arrow) %>% reduce(left_join, by ='dateTime')
Q<-subset(Q1, select = c(dateTime, Flow_Inst.x, Flow_Inst.y, Flow_Inst.x.x, Flow_Inst.y.y, Flow_Inst))
colnames(Q)<- c("dateTime", "Boise_twnSpr", "SF_featherville", "Mores", "Anderson", "SF_ArrowRock")
#quicklook at data
plot(Q$dateTime, Q$Boise_twnSpr, type="l", col="blue")
lines(Q$dateTime, Q$SF_featherville, col="green")
lines(Q$dateTime, Q$Mores,  col="red")
#save
write.csv(Q, file="BRB_Q_wy87-17.csv")
cd()
wd()
cwd()
which(is.na(Q$Boise_twnSpr))
View(siteInfo)
which(is.na(Q$SF_featherville))
nas<- which(is.na(Q$SF_featherville))
?strptime
minutes<-as.numeric(format(Q$dateTime, format= "%M"))
BoiseTwnSprings_hrly <-  Q$Boise_twnSpr %>%
filter(Q$Boise_twnSpr, minutes == 0)
#subset to hourly
library(dplyr)
minutes<-as.numeric(format(Q$dateTime, format= "%M"))
BoiseTwnSprings_hrly <-  Q$Boise_twnSpr %>%
filter(Q$Boise_twnSpr, minutes == 0)
minutes<-format(Q$dateTime, format= "%M")
BoiseTwnSprings_hrly <-  Q$Boise_twnSpr %>%
filter(Q$Boise_twnSpr, minutes == 0)
type(Q$Boise_twnSpr )
class(Q$Boise_twnSpr)
BoiseTwnSprings_hrly <- filter(Q$Boise_twnSpr, minutes == 0)
minutes<-as.numeric(format(Q$dateTime, format= "%M"))
BoiseTwnSprings=matrix(data=NA, nrow = length(Q$Boise_twnSpr), ncol = 2)
for (i in length(Q$Boise_twnSpr)){
if(minutes[i] == 0){
BoiseTwnSprings$Date[i]<-Q$dateTime[i]
BoiseTwnSprings$Q[i] <- Q$Boise_twnSpr[i]
}
}
View(BoiseTwnSprings)
minutes[4]
minutes[5]
Qdf<-data.frame(Q)
View(Qdf)
Qdf<-data.frame(Q)
BoiseTwnSprings$Date<-filter(Qdf$dateTime, minutes ==0)
class(Qdf)
Qdf<-table(Q)
BoiseTwnSprings$Date<-filter(Qdf$dateTime, minutes ==0)
class(Qdf)
BoiseTwnSprings$Date<-filter(Qdf$dateTime, minutes == 0)
View(Qdf)
filter_.POSIXt <- dplyr:::filter_.Date
Qdf<-table(Q)
BoiseTwnSprings$Date<-filter(Qdf$dateTime, minutes == 0)
Qdf<-as.data.table(Q)
library(data.table)
Qdf<-tbl(Q)
Qdf<-tbl(Q, "R_data_frame")
Qts<-tbl(Q$Boise_twnSpr, "R_data_frame")
Qts<-tbl(Q$Boise_twnSpr)
zz=[minutes ==0]
zz=minutes[minutes == 0]
length(zz)
BoiseTwnSprings=matrix(data=NA, nrow = 175122, ncol = 2)
BoiseTwnSprings$Date<-Q$dateTime[minutes ==0]
BoiseTwnSprings$Q <- Q$Boise_twnSpr[minutes ==0]
View(BoiseTwnSprings)
View(BoiseTwnSprings)
View(BoiseTwnSprings)
BoiseTwnSprings[1,]<- Q$Boise_twnSpr[minutes == 0]
View(BoiseTwnSprings)
View(BoiseTwnSprings)
View(BoiseTwnSprings)
BoiseTS<-Q$dateTime[minutes ==0]
library(dataRetrieval)
library(tidyverse)
start=as.Date("1987-10-01")
end= as.Date("2017-09-30")
### Data Organized by Individual Sites
pCode <- "00060"
Boise_twnSpr <- readNWISuv(siteNumbers = 13185000, parameterCd = pCode, startDate = start, endDate = end) %>% renameNWISColumns() %>% data.frame
Boise_twnSpr <- readNWISuv(siteNumbers = 13185000, parameterCd = pCode, startDate = start, endDate = end) %>% renameNWISColumns() %>% data.frame
minutes<-as.numeric(format(Q$dateTime, format= "%M"))
BoiseTS_hrly<-Boise_twnSpr$Flow_Inst[minutes ==0]
BoiseTS_date<- Boise_twnSpr$dateTime[minutes == 0]
View(Boise_twnSpr)
#subset to hourly
minutes<-as.numeric(format(Boise_twnSpr$dateTime, format= "%M"))
BoiseTS_hrly<-Boise_twnSpr$Flow_Inst[minutes ==0]
BoiseTS_date<- Boise_twnSpr$dateTime[minutes == 0]
BoiseTS_date<- as.Date(Boise_twnSpr$dateTime[minutes == 0])
Q_hrly<-Boise_twnSpr$Flow_Inst[minutes ==0]
date<- as.Date(Boise_twnSpr$dateTime[minutes == 0])
Bois_TS<-data.frame(date,Q_hrly)
write.csv(Bois_TS, file="BoiseTwinSprings_hrlyQ_wy87-17.csv")
setwd("~/Documents/GitRepos/ReservoirModeling")
#--------------------------------------
# Import reservoir data
#--------------------------------------
# missing data was replaced by average of bracketing values
res<-read.csv("Data/BRB_reservoir_data_1997-2018_noleap.csv")
res$Date <-as.Date(res$Date, format ="%m/%d/%y")
res$totAF<- res$andAF +res$arkAF +res$lucAF
res$qoV<-res$qo*24*60*60*.0000229569 #convert from flow rate (cfs) to volume (acre-feet)
res$resid<- res$in_unreg- res$in_computed
res$Y = as.numeric(format(res$Date, format = "%Y"))
res$M = as.numeric(format(res$Date, format = "%m"))
res$WY[res$M <10]= res$Y[res$M <10]
res$WY[res$M >= 10] = res$Y[res$M >= 10]+1
lowell<-read.csv("Data/lowell_data.csv")
res$low<-lowell$low_af
# load Rule Curve data --------
fv<-read.csv("Data/ForecastVol.csv")
fcVol<-read.csv("Data/FloodControlVol.csv", header=FALSE) #DOY, date, volumes
fcVol[,3:36]<- fcVol[,3:36]*1000 #bc flood control space is in 1000 ac-ft see plate 7-1 in the WCM
fcVol$V2<- as.Date(fcVol$V2, format ="%m/%d/%Y")
prj<-read.csv("Data/Inflw_prj.csv") #coefficients for projection eqn
prjAP<-read.csv("Data/Inflw_prjAPril1.csv") #coefficients for projection eqn after April 1
wfc<-read.csv("Data/plate7-2.csv") #winter flood control space
qlim<- read.csv("Data/MaxQ.csv", header = FALSE) #discharge mins and maxes
#conversions from vol to flow (ac-ft to cfs)
v2f<-43560.000443512/(24*60*60)
f2v<-24*60*60*.0000229569
#Reservoir Storage from WCM
minQ<-240
maxAF<-1010188
minS<-  41000 +11630+ 28767 #total inactive capacity AND, ARK, LP
#subset (DOY 1: July 31st) from full timeseries -----
jul=196 #change to 212 #july 31st once update fcVol csv
reps <-100
idx<-which(res$doy >= 1 & res$doy <= jul)
rows<- length(idx)
FC<- data.frame(res$doy[idx],res$WY[idx], res$totAF[idx], res$in_unreg[idx], res$qo[idx])
colnames(FC)<-c("doy", "WY", "AF", "Q", "Qo")
yrs<- 1998:2018
#calculate daily forecast values
forecast<-read.csv("Data/LP_coordinatedForecasts.csv")
volF<-vector(length = nrow(FC))
for (i in 1:nrow(FC)){
if (any(forecast$wy == FC$WY[i] & forecast$doy == FC$doy[i])){
ii=which(forecast$wy == FC$WY[i] & forecast$doy == FC$doy[i])
volF[i] <- forecast$ForecastVol[ii]
} else{volF[i] <- volF[i-1] - FC$Q[i-1]*f2v}
}
FC<-cbind(FC, volF)
FC$volF[FC$volF < 0] <- 0
#find the index of the first doy
doy1<-matrix(data=NA, ncol=1, nrow=21)
for (wy in 1:21){
doy1[wy]<- which(FC$WY == yrs[wy] & FC$doy == 1)
}
##--------------------------------------
#       DEFINE FUNCTIONS
##--------------------------------------
# REQUIRED storage - lookup day of year, inflow volume ----
# plate 7-1 and plate 7-3 - Needs sum of timeseries
reqStor<- function(sumQin,doy){
fvol<-round(sumQin/1000000, digits=1)
fcol<- as.numeric(fv$col[fv$fv == fvol])
fcs<- as.numeric(fcVol[doy, fcol+2]) ##PROBLEM when volume forecast == 0 ***
#Winter flood control space (low flow years Plate 7-2) ----
if (doy < 91 && fvol > 1.2 && fvol < 1.8){
wcol<- as.numeric(fv$wcol[fv$wfc == fvol])
fcs<- as.numeric(wfc[doy,wcol])
}
if (is.na(fcs) == TRUE){
fcs<- as.numeric(fcVol[doy, fcol+2])
}
#required flood control space (storage volume)
return(fcs)
}
#predict max storage in the next m days
predMaxS<- function(){
for (day in 1:jul){
volF<<- FC$volF[FC$WY == yrs[wy] & FC$doy == day] #todays forecasted inflow
count=0
if (volF >= 0 && day< jul){
for (it in day:(day+m-1)){
count=count+1
vF = volF - (volF/(jul-day))*(day-it) #predict maxS given equal distribution of inflow
reqS<- reqStor(vF, it)
maxS[day, count] <- (maxAF-reqS) #max storage today given the whole years inflow
}
} else {storD <- 0}
maxS[is.na(maxS)]<- maxAF
}
return(maxS)
}
#determine minimum daily release before April 1
minRelease<- function(){
ix= which(prj$start <= day & prj$end >= day)
vol1 = volF*prj$b[ix] + prj$c[ix]
if (prj$start[ix] != day){
vol2 = volF*prj$b[ix+1] + prj$c[ix+1]
frac = (day - prj$start[ix])/(prj$end[ix]-prj$start[ix])
volFmar <-  frac*vol1 + (1-frac)*vol2
} else {volFmar = vol1}
volFresid <- volF - volFmar
FCvolAP<- reqStor(volFresid, 91) #flood control space required on april 1
minEvac<- FCvolAP - availStor[day] #minimum evaculation btw today and April 1
minReleaseVol <- minEvac+volFmar
Qmin<- (minReleaseVol*v2f)/(jul-day+1) #associated  qmin
##If statements that constrain for high flows and ramp rates?
}
#determine minimum daily release after April 1
minReleaseApril<-function(){
ix30 = findInterval(day, prjAP$doy)
ix15=ix30-1
volF_target15 <- volF*prjAP$b[ix15] + prjAP$c[ix15]
volF_target30 <- volF*prjAP$b[ix30] + prjAP$c[ix30]
residual15<- volF-volF_target15
residual30<- volF- volF_target30
if (day < jul-30){
FCvol30<- reqStor(residual30, day+30) #required storage space
minEvac30 <- FCvol30 - availStor[day]
minReleaseVol30 <- minEvac30 + volF_target30
q30<-(minReleaseVol30*v2f)/(jul-day+1)
} else {q30 <- minQ}
if (day < jul-15){
FCvol15<-reqStor(residual15, day+15)
minEvac15 <- FCvol15 - availStor[day]
minReleaseVol15 <- minEvac15 + volF_target15
q15<-(minReleaseVol15*v2f)/(jul-day+1)
} else {q15 <- minQ}
Qmin<- max(q15, q30)
}
forecastS<-function(){
if (day > s+1){
dsdt= (stor[day] - stor[day-s])/s
storF[day] <<- (dsdt*m)+stor[day] #forecast what the storage would be in s days given previous âˆ† in S
}
}
#evaluate change in storage to prevent going over maxS
evalS<- function(Qin, day, stor, maxS, Qmin){
if (storF[day] >= maxS[day,m] && day > s+1){ #&& day <188
dsdtMax= (storF[day] - maxS[day,m])/s
qo[day] = Qmin[day] + (dsdtMax*v2f)
flag = 'TRUE' #true we need to increase ramp rates to get rid of the water
} else {qo[day]= Qmin[day]
flag='FALSE'}
if (stor[day] > maxAF){
addQ = (stor[day] - maxAF)*v2f
minFCq[day] = minFCq[day] + addQ
flag= 'TRUE'
} else {flag='FALSE'}
#if the calculated discharge is greater than +/- 500 set it to +/- 500
if (flag == 'TRUE'){ #going over maxS or maxAF
ramp= 1000
} else {ramp = 500}
if (qo[day] > qo[day-1]+ramp && day > 2){
qo[day] = qo[day-1]+ramp
} else if (qo[day] < qo[day-1]-500 && day > 2){
qo[day] = qo[day-1]-500}
if (availStor[day] <= (1000*v2f)){ #this puts a hard constraints on not topping the dam - but doiesnt work 21 times
qo[day] = qo[day] + 1000
availStor[day] = availStor[day] + 1000*f2v
stor[day] = stor[day] - (1000*f2v)
}
dS[day] <- (Qin[day]- qo[day])*f2v
if (stor[day] <= minS){ #dont let storage go below the minimum
qo[day] <- minQ
dS[day] <- -minQ*f2v
}
if (day < jul){
stor[day+1]<-stor[day] + dS[day]  #AF in the reservoir
}
outlist<-(list("stor"=stor, "dS"=dS, "qo"=qo, "storF"=storF))
}
s=5 #number of prior days to estimate change in storage
m=10 #planning window
#-------------------------------------------------------------
#   set up blank matricies
#------------------------------------------------------------
resS=matrix(data=NA, nrow = jul, ncol = 1)
stor=matrix(data=NA, nrow = jul, ncol = 1)
maxS=matrix(data=NA, nrow = jul, ncol = m)
dS=matrix(data=NA, nrow = jul, ncol = 1)
minFCq=matrix(data=NA, nrow = jul, ncol = 1)
qo=matrix(data=NA, nrow = jul, ncol = 1)
storF=matrix(data=NA, nrow = jul, ncol = 1)
availStor=matrix(data=NA, nrow = jul, ncol = 1)
#---------------------------------------------------------------
#   determine change in storage and outflow for any day of year
#---------------------------------------------------------------
#select Qin from matrix or array? - turn into funtion
for (wy in 1:20){
stor[1]<-FC$AF[doy1[wy]] #initialize with actual storage on Jan 1
Qin<- FC$Q[FC$WY == yrs[wy]]
maxS<-predMaxS()
for (day in 1:jul){
volF<- FC$volF[FC$WY == yrs[wy] & FC$doy == day] #todays forecasted inflow
availStor[day] <- maxAF-stor[day]
# Min flood control release for storage goals on April 1 and every 15 days after
if (day < 91){
minFCq[day]<-minRelease()
} else {
minFCq[day]<-minReleaseApril()
}
#minimum discharge is 240
if (minFCq[day] < minQ){
minFCq[day] <- minQ
}
forecastS()
resS <- evalS(Qin, day, stor, maxS, minFCq)
qo[day]<-resS$qo[day]
dS[day]<- resS$dS[day]
if (day < jul){
stor[day+1]<-resS$stor[day+1] #AF in the reservoir
}
}
#save intial run output ----  # change for debugging? - put clear matricies at beginning
FC$qo[FC$WY == yrs[wy]]<-qo[,]
FC$stor[FC$WY == yrs[wy]]<-stor[,]
FC$availS[FC$WY == yrs[wy]]<-availStor[,]
FC$maxS[FC$WY == yrs[wy]]<-maxS[,1]
FC$Qmin[FC$WY == yrs[wy]]<-minFCq[,]
FC$storF[FC$WY == yrs[wy]]<-storF[,]
}
exceed <- which(FC$stor > FC$maxS)
exceedDate=matrix(data=NA, nrow = length(exceed), ncol = 2)
exceedDate[,1] <- FC$WY[exceed]
exceedDate[,2] <- FC$doy[exceed]
hist(exceedDate[,2])
topped <- which(FC$stor > maxAF)
FC$topped<- FC$stor > maxAF
hist(FC$doy[FC$topped == 'TRUE'])
#plot the initial results
for(wy in 1:4){
plot(FC$maxS[FC$WY == yrs[wy]], type='l', ylim=c(300000, 1010200))
lines(FC$stor[FC$WY == yrs[wy]], col='orange')
lines(FC$AF[FC$WY == yrs[wy]], col='green')
#plot(Qmin, type='l', col='blue', ylim=c(0,16000))
# plot(FC$qo[FC$WY == yrs[wy]], type='l', lty=3, col='orange', ylim=c(0,16000))
#  lines(qlim[,2], type='l', lty=3, col='grey17')
# lines(FC$Qo[FC$WY == yrs[wy]], type='l', lty=5, lwd='1', col='skyblue1') #manged outflow
}
library(ggplot2)
library(reshape2)
library(gridExtra)
library(gtable)
library(grid)
fill<- rep(c("Modeled", "Observed", "Max"), each=196)
datelab<-seq(as.Date("1997-01-01"), as.Date("1997-07-15"), by="1 day")
x<- datelab
x2<- rep(datelab, times=4)
qs<-rep(c("Inflow", "Limit","Modeled Q", "Observed Q"), each=196)
gnames<- c("g98", "g99", "g00", 'g01', "g02", "g03", "g04","g05", 'g06', "g07", "g08", "g09", "g10", "g11", "g12", "g13", "g14", "g15", "g16", "g17")
plotfn<- function(wy){
vol<-(c(FC$storN[FC$WY == yrs[wy]],FC$AF[FC$WY == yrs[wy]],FC$maxS[FC$WY == yrs[wy]]))/10000
df <- data.frame(fill,x,vol)
q<- c(FC$Q[FC$WY == yrs[wy]], qlim[1:196,2],FC$qoN[FC$WY == yrs[wy]], FC$Qo[FC$WY == yrs[wy]])/1000
dfQ<-data.frame(q, x2, qs)
ps<-ggplot(df, aes(x=x, y=vol, fill=fill)) +
geom_hline(yintercept=maxAF/10000,linetype="dashed")+
geom_area(position = "identity")+
scale_fill_manual(values = alpha(c("#7fcdbb", "#ce1256", "#15D1FF"), c(0.65,1,0.70)))+ #green red blue "#7fcdbb", "#ce1256", "#2c7fb8" #abdda4
scale_x_date(date_breaks = "1 month", date_labels =  "%b", expand=c(0,0))+
xlab(NULL)+
theme_classic()+
theme(axis.text.x = element_blank())+
theme(legend.position="none")+
ylab("Storage (10,000 ac-ft)")+
coord_cartesian(ylim=c(minS/10000,maxAF/10000))
pq<-ggplot(dfQ, aes(x=x2, y=q, colour=qs, group= qs, linetype = qs))+
geom_line() +
scale_color_manual(values=c("#1018A4","#969696","#ce1256", "#15B9FF"))+
scale_linetype_manual(values=c("solid","dashed","solid","solid")) +
scale_x_date(date_breaks = "1 month", date_labels =  "%b", expand=c(0,0))+
theme_classic()+
theme(legend.position="none") +
scale_y_continuous(breaks=seq(0,12,2))+
ylab("Discharge (1,000 cfs)")+
xlab("Date")
gs<-ggplotGrob(ps)
gq<-ggplotGrob(pq)
nam<-paste("g",wy, sep="")
assign(nam, rbind(gs, gq, size = "first"), envir = .GlobalEnv)
gg<-get(nam)
gg$widths <- unit.pmax(gs$widths, gq$widths)
grid.newpage()
grid.draw(gg)
}
#plotfn(20)
for (wy in 1:20){
plotfn(wy)
}
grid.arrange(g1, g2, g3, g4, g5, g6, g7, g8, g9, g10, nrow=1)
grid.arrange(g11, g12, g13, g14, g15, g16, g17, g18, g19, g20, nrow=1)
vol<-(c(stor[1:195,wy],afmg[1:195,wy],maxS[1:195,wy]))/10000
df <- data.frame(fill,x,vol)
ps<-ggplot(df, aes(x=x, y=vol, fill=fill)) +
geom_hline(yintercept=26.4900,linetype="dashed")+
geom_area(position = "identity")+
scale_fill_manual(values = alpha(c("#7fcdbb", "#ce1256", "#15D1FF"), c(0.65,1,0.70)))+ #green red blue "#7fcdbb", "#ce1256", "#2c7fb8" #abdda4
scale_x_date(date_breaks = "1 month", date_labels =  "%b", expand=c(0,0))+
xlab(NULL)+
theme_classic()+
theme(axis.text.x = element_blank())+
theme(legend.position="none")+
ylab("Storage (10,000 ac-ft)")+
coord_cartesian(ylim=c(0,27), expand=c(0,0))
View(FC)
fill<- rep(c("Modeled", "Observed", "Max"), each=196)
datelab<-seq(as.Date("1997-01-01"), as.Date("1997-07-15"), by="1 day")
x<- datelab
x2<- rep(datelab, times=4)
qs<-rep(c("Inflow", "Limit","Modeled Q", "Observed Q"), each=196)
gnames<- c("g98", "g99", "g00", 'g01', "g02", "g03", "g04","g05", 'g06', "g07", "g08", "g09", "g10", "g11", "g12", "g13", "g14", "g15", "g16", "g17")
plotfn<- function(wy){
vol<-(c(FC$stor[FC$WY == yrs[wy]],FC$AF[FC$WY == yrs[wy]],FC$maxS[FC$WY == yrs[wy]]))/10000
df <- data.frame(fill,x,vol)
q<- c(FC$Q[FC$WY == yrs[wy]], qlim[1:196,2],FC$qo[FC$WY == yrs[wy]], FC$Qo[FC$WY == yrs[wy]])/1000
dfQ<-data.frame(q, x2, qs)
ps<-ggplot(df, aes(x=x, y=vol, fill=fill)) +
geom_hline(yintercept=maxAF/10000,linetype="dashed")+
geom_area(position = "identity")+
scale_fill_manual(values = alpha(c("#7fcdbb", "#ce1256", "#15D1FF"), c(0.65,1,0.70)))+ #green red blue "#7fcdbb", "#ce1256", "#2c7fb8" #abdda4
scale_x_date(date_breaks = "1 month", date_labels =  "%b", expand=c(0,0))+
xlab(NULL)+
theme_classic()+
theme(axis.text.x = element_blank())+
theme(legend.position="none")+
ylab("Storage (10,000 ac-ft)")+
coord_cartesian(ylim=c(minS/10000,maxAF/10000))
pq<-ggplot(dfQ, aes(x=x2, y=q, colour=qs, group= qs, linetype = qs))+
geom_line() +
scale_color_manual(values=c("#1018A4","#969696","#ce1256", "#15B9FF"))+
scale_linetype_manual(values=c("solid","dashed","solid","solid")) +
scale_x_date(date_breaks = "1 month", date_labels =  "%b", expand=c(0,0))+
theme_classic()+
theme(legend.position="none") +
scale_y_continuous(breaks=seq(0,12,2))+
ylab("Discharge (1,000 cfs)")+
xlab("Date")
gs<-ggplotGrob(ps)
gq<-ggplotGrob(pq)
nam<-paste("g",wy, sep="")
assign(nam, rbind(gs, gq, size = "first"), envir = .GlobalEnv)
gg<-get(nam)
gg$widths <- unit.pmax(gs$widths, gq$widths)
grid.newpage()
grid.draw(gg)
}
#plotfn(20)
for (wy in 1:20){
plotfn(wy)
}
grid.arrange(g1, g2, g3, g4, g5, g6, g7, g8, g9, g10, nrow=1)
grid.arrange(g11, g12, g13, g14, g15, g16, g17, g18, g19, g20, nrow=1)
library(grid)
grid.arrange(g1, g2, g3, g4, g5, g6, g7, g8, g9, g10, nrow=1)
library(ggplot2)
library(reshape2)
library(gridExtra)
library(gtable)
library(grid)
install.packages("gridExtra")
library(gridExtra)
grid.arrange(g1, g2, g3, g4, g5, g6, g7, g8, g9, g10, nrow=1)
grid.arrange(g11, g12, g13, g14, g15, g16, g17, g18, g19, g20, nrow=1)
