dsdtMax= (storF[day] - maxS[day,m])/s
qo[day] = Qmin[day] + (dsdtMax*v2f)
flag = 'TRUE' #true we need to increase ramp rates to get rid of the water
} else {qo[day]= Qmin[day]
flag='FALSE'}
if (stor[day] > maxAF){
addQ = (stor[day] - maxAF)*v2f
minFCq[day] = minFCq[day] + addQ
flag= 'TRUE'
} else {flag='FALSE'}
#if the calculated discharge is greater than +/- 500 set it to +/- 500
if (flag == 'TRUE'){ #going over maxS or maxAF
ramp= 1000
} else {ramp = 500}
if (qo[day] > qo[day-1]+ramp && day > 2){
qo[day] = qo[day-1]+ramp
} else if (qo[day] < qo[day-1]-500 && day > 2){
qo[day] = qo[day-1]-500}
dS[day] <- (Qin[day]- qo[day])*f2v
if (stor[day] <= minS){ #dont let storage go below the minimum
qo[day] <- minQ
dS[day] <- -minQ*f2v
}
if (day < jul){
stor[day+1]<-stor[day] + dS[day]  #AF in the reservoir
}
outlist<-(list("stor"=stor, "dS"=dS, "qo"=qo, "storF"=storF))
}
s=5 #number of prior days to estimate change in storage
m=10 #planning window
#-------------------------------------------------------------
#   set up blank matricies
#------------------------------------------------------------
resS=matrix(data=NA, nrow = jul, ncol = 1)
stor=matrix(data=NA, nrow = jul, ncol = 1)
maxS=matrix(data=NA, nrow = jul, ncol = m)
dS=matrix(data=NA, nrow = jul, ncol = 1)
minFCq=matrix(data=NA, nrow = jul, ncol = 1)
qo=matrix(data=NA, nrow = jul, ncol = 1)
storF=matrix(data=NA, nrow = jul, ncol = 1)
availStor=matrix(data=NA, nrow = jul, ncol = 1)
#---------------------------------------------------------------
#   determine change in storage and outflow for any day of year
#---------------------------------------------------------------
#select Qin from matrix or array? - turn into funtion
for (wy in 1:20){
stor[1]<-FC$AF[doy1[wy]] #initialize with actual storage on Jan 1
Qin<- FC$Q[FC$WY == yrs[wy]]
maxS<-predMaxS()
for (day in 1:jul){
volF<- FC$volF[FC$WY == yrs[wy] & FC$doy == day] #todays forecasted inflow
availStor[day] <- maxAF-stor[day]
# Min flood control release for storage goals on April 1 and every 15 days after
if (day < 91){
minFCq[day]<-minRelease()
} else {
minFCq[day]<-minReleaseApril()
}
#minimum discharge is 240
if (minFCq[day] < minQ){
minFCq[day] <- minQ
}
forecastS()
resS <- evalS(Qin, day, stor, maxS, minFCq)
qo[day]<-resS$qo[day]
dS[day]<- resS$dS[day]
if (day < jul){
stor[day+1]<-resS$stor[day+1] #AF in the reservoir
}
}
#save intial run output ----  # change for debugging? - put clear matricies at beginning
FC$qo[FC$WY == yrs[wy]]<-qo[,]
FC$stor[FC$WY == yrs[wy]]<-stor[,]
FC$availS[FC$WY == yrs[wy]]<-availStor[,]
FC$maxS[FC$WY == yrs[wy]]<-maxS[,1]
FC$Qmin[FC$WY == yrs[wy]]<-minFCq[,]
FC$storF[FC$WY == yrs[wy]]<-storF[,]
}
topped <- which(FC$stor > maxAF)
FC$topped<- FC$stor > maxAF
plot(volF[volF == 0], stor[volF == 0])
plot(FC$volF[FC$volF == 0], FC$stor[FC$volF == 0])
plot(FC$volF[FC$topped == 'TRUE'], FC$stor[FC$topped == 'TRUE'])
View(fv)
View(fcVol)
1000*v2f
1000*f2v
#evaluate change in storage to prevent going over maxS
evalS<- function(Qin, day, stor, maxS, Qmin){
if (storF[day] >= maxS[day,m] && day > s+1){ #&& day <188
dsdtMax= (storF[day] - maxS[day,m])/s
qo[day] = Qmin[day] + (dsdtMax*v2f)
flag = 'TRUE' #true we need to increase ramp rates to get rid of the water
} else {qo[day]= Qmin[day]
flag='FALSE'}
if (stor[day] > maxAF){
addQ = (stor[day] - maxAF)*v2f
minFCq[day] = minFCq[day] + addQ
flag= 'TRUE'
} else {flag='FALSE'}
#if the calculated discharge is greater than +/- 500 set it to +/- 500
if (flag == 'TRUE'){ #going over maxS or maxAF
ramp= 1000
} else {ramp = 500}
if (qo[day] > qo[day-1]+ramp && day > 2){
qo[day] = qo[day-1]+ramp
} else if (qo[day] < qo[day-1]-500 && day > 2){
qo[day] = qo[day-1]-500}
if (availStor[day] <= (1000*v2f)){
qo[day] = minFCq[day] + 1000
availStor[day] = availStor[day] + 1000*f2v
stor[day] = stor[day] - (1000*f2v)
}
dS[day] <- (Qin[day]- qo[day])*f2v
if (stor[day] <= minS){ #dont let storage go below the minimum
qo[day] <- minQ
dS[day] <- -minQ*f2v
}
if (day < jul){
stor[day+1]<-stor[day] + dS[day]  #AF in the reservoir
}
outlist<-(list("stor"=stor, "dS"=dS, "qo"=qo, "storF"=storF))
}
s=5 #number of prior days to estimate change in storage
m=10 #planning window
#-------------------------------------------------------------
#   set up blank matricies
#------------------------------------------------------------
resS=matrix(data=NA, nrow = jul, ncol = 1)
stor=matrix(data=NA, nrow = jul, ncol = 1)
maxS=matrix(data=NA, nrow = jul, ncol = m)
dS=matrix(data=NA, nrow = jul, ncol = 1)
minFCq=matrix(data=NA, nrow = jul, ncol = 1)
qo=matrix(data=NA, nrow = jul, ncol = 1)
storF=matrix(data=NA, nrow = jul, ncol = 1)
availStor=matrix(data=NA, nrow = jul, ncol = 1)
#---------------------------------------------------------------
#   determine change in storage and outflow for any day of year
#---------------------------------------------------------------
#select Qin from matrix or array? - turn into funtion
for (wy in 1:20){
stor[1]<-FC$AF[doy1[wy]] #initialize with actual storage on Jan 1
Qin<- FC$Q[FC$WY == yrs[wy]]
maxS<-predMaxS()
for (day in 1:jul){
volF<- FC$volF[FC$WY == yrs[wy] & FC$doy == day] #todays forecasted inflow
availStor[day] <- maxAF-stor[day]
# Min flood control release for storage goals on April 1 and every 15 days after
if (day < 91){
minFCq[day]<-minRelease()
} else {
minFCq[day]<-minReleaseApril()
}
#minimum discharge is 240
if (minFCq[day] < minQ){
minFCq[day] <- minQ
}
forecastS()
resS <- evalS(Qin, day, stor, maxS, minFCq)
qo[day]<-resS$qo[day]
dS[day]<- resS$dS[day]
if (day < jul){
stor[day+1]<-resS$stor[day+1] #AF in the reservoir
}
}
#save intial run output ----  # change for debugging? - put clear matricies at beginning
FC$qo[FC$WY == yrs[wy]]<-qo[,]
FC$stor[FC$WY == yrs[wy]]<-stor[,]
FC$availS[FC$WY == yrs[wy]]<-availStor[,]
FC$maxS[FC$WY == yrs[wy]]<-maxS[,1]
FC$Qmin[FC$WY == yrs[wy]]<-minFCq[,]
FC$storF[FC$WY == yrs[wy]]<-storF[,]
}
exceed <- which(FC$stor > FC$maxS)
exceedDate=matrix(data=NA, nrow = length(exceed), ncol = 2)
exceedDate[,1] <- FC$WY[exceed]
exceedDate[,2] <- FC$doy[exceed]
hist(exceedDate[,2])
topped <- which(FC$stor > maxAF)
FC$topped<- FC$stor > maxAF
#plot the initial results
for(wy in 1:10){
plot(FC$maxS[FC$WY == yrs[wy]], type='l', ylim=c(300000, 1010200))
lines(FC$stor[FC$WY == yrs[wy]], col='orange')
lines(FC$AF[FC$WY == yrs[wy]], col='green')
#plot(Qmin, type='l', col='blue', ylim=c(0,16000))
plot(FC$qo[FC$WY == yrs[wy]], type='l', lty=3, col='orange', ylim=c(0,16000))
lines(qlim[,2], type='l', lty=3, col='grey17')
lines(FC$Qo[FC$WY == yrs[wy]], type='l', lty=5, lwd='1', col='skyblue1') #manged outflow
}
View(FC)
minS
#evaluate change in storage to prevent going over maxS
evalS<- function(Qin, day, stor, maxS, Qmin){
if (storF[day] >= maxS[day,m] && day > s+1){ #&& day <188
dsdtMax= (storF[day] - maxS[day,m])/s
qo[day] = Qmin[day] + (dsdtMax*v2f)
flag = 'TRUE' #true we need to increase ramp rates to get rid of the water
} else {qo[day]= Qmin[day]
flag='FALSE'}
if (stor[day] > maxAF){
addQ = (stor[day] - maxAF)*v2f
minFCq[day] = minFCq[day] + addQ
flag= 'TRUE'
} else {flag='FALSE'}
#if the calculated discharge is greater than +/- 500 set it to +/- 500
if (flag == 'TRUE'){ #going over maxS or maxAF
ramp= 1000
} else {ramp = 500}
if (qo[day] > qo[day-1]+ramp && day > 2){
qo[day] = qo[day-1]+ramp
} else if (qo[day] < qo[day-1]-500 && day > 2){
qo[day] = qo[day-1]-500}
if (availStor[day] <= (1000*v2f)){ #this is an attempt at putting hard constraints on not topping the dam - but doesn't always work
qo[day] = qo[day] + 1000
availStor[day] = availStor[day] + 1000*f2v
stor[day] = stor[day] - (1000*f2v)
}
dS[day] <- (Qin[day]- qo[day])*f2v
if (stor[day] <= minS){ #dont let storage go below the minimum
qo[day] <- minQ
dS[day] <- -minQ*f2v
}
if (day < jul){
stor[day+1]<-stor[day] + dS[day]  #AF in the reservoir
}
outlist<-(list("stor"=stor, "dS"=dS, "qo"=qo, "storF"=storF))
}
s=5 #number of prior days to estimate change in storage
m=10 #planning window
#-------------------------------------------------------------
#   set up blank matricies
#------------------------------------------------------------
resS=matrix(data=NA, nrow = jul, ncol = 1)
stor=matrix(data=NA, nrow = jul, ncol = 1)
maxS=matrix(data=NA, nrow = jul, ncol = m)
dS=matrix(data=NA, nrow = jul, ncol = 1)
minFCq=matrix(data=NA, nrow = jul, ncol = 1)
qo=matrix(data=NA, nrow = jul, ncol = 1)
storF=matrix(data=NA, nrow = jul, ncol = 1)
availStor=matrix(data=NA, nrow = jul, ncol = 1)
#---------------------------------------------------------------
#   determine change in storage and outflow for any day of year
#---------------------------------------------------------------
#select Qin from matrix or array? - turn into funtion
for (wy in 1:20){
stor[1]<-FC$AF[doy1[wy]] #initialize with actual storage on Jan 1
Qin<- FC$Q[FC$WY == yrs[wy]]
maxS<-predMaxS()
for (day in 1:jul){
volF<- FC$volF[FC$WY == yrs[wy] & FC$doy == day] #todays forecasted inflow
availStor[day] <- maxAF-stor[day]
# Min flood control release for storage goals on April 1 and every 15 days after
if (day < 91){
minFCq[day]<-minRelease()
} else {
minFCq[day]<-minReleaseApril()
}
#minimum discharge is 240
if (minFCq[day] < minQ){
minFCq[day] <- minQ
}
forecastS()
resS <- evalS(Qin, day, stor, maxS, minFCq)
qo[day]<-resS$qo[day]
dS[day]<- resS$dS[day]
if (day < jul){
stor[day+1]<-resS$stor[day+1] #AF in the reservoir
}
}
#save intial run output ----  # change for debugging? - put clear matricies at beginning
FC$qo[FC$WY == yrs[wy]]<-qo[,]
FC$stor[FC$WY == yrs[wy]]<-stor[,]
FC$availS[FC$WY == yrs[wy]]<-availStor[,]
FC$maxS[FC$WY == yrs[wy]]<-maxS[,1]
FC$Qmin[FC$WY == yrs[wy]]<-minFCq[,]
FC$storF[FC$WY == yrs[wy]]<-storF[,]
}
exceed <- which(FC$stor > FC$maxS)
exceedDate=matrix(data=NA, nrow = length(exceed), ncol = 2)
exceedDate[,1] <- FC$WY[exceed]
exceedDate[,2] <- FC$doy[exceed]
hist(exceedDate[,2])
topped <- which(FC$stor > maxAF)
FC$topped<- FC$stor > maxAF
topped <- which(FC$stor > maxAF)
FC$topped<- FC$stor > maxAF
for(wy in 1:10){
plot(FC$maxS[FC$WY == yrs[wy]], type='l', ylim=c(300000, 1010200))
lines(FC$stor[FC$WY == yrs[wy]], col='orange')
lines(FC$AF[FC$WY == yrs[wy]], col='green')
#plot(Qmin, type='l', col='blue', ylim=c(0,16000))
plot(FC$qo[FC$WY == yrs[wy]], type='l', lty=3, col='orange', ylim=c(0,16000))
lines(qlim[,2], type='l', lty=3, col='grey17')
lines(FC$Qo[FC$WY == yrs[wy]], type='l', lty=5, lwd='1', col='skyblue1') #manged outflow
}
hist(FC$doy[FC$topped = 'TRUE'])
hist(FC$doy[FC$topped == 'TRUE'])
#plot the initial results
for(wy in 1:21){
plot(FC$maxS[FC$WY == yrs[wy]], type='l', ylim=c(300000, 1010200))
lines(FC$stor[FC$WY == yrs[wy]], col='orange')
lines(FC$AF[FC$WY == yrs[wy]], col='green')
#plot(Qmin, type='l', col='blue', ylim=c(0,16000))
# plot(FC$qo[FC$WY == yrs[wy]], type='l', lty=3, col='orange', ylim=c(0,16000))
#  lines(qlim[,2], type='l', lty=3, col='grey17')
# lines(FC$Qo[FC$WY == yrs[wy]], type='l', lty=5, lwd='1', col='skyblue1') #manged outflow
}
#---------------
# Download all USGS data from the Upper Boise Basin
# Kendra Kaiser January 9th 2018
#---------------
# HUC codes: 17050111	North and Middle Forks Boise; 17050112	Boise-Mores; 17050113	South Fork Boise - there should be a way to dnld data w these instead of manually finding all the relevant gauges
# siteIDs: "13185000" Boise NR Twin Springs, "13186000" SF Boise NR Featherville, "13190500" SF Boise @ Anderson Ranch,
# "13192200" SF Boise @ Neal Bridge nr Arrowrock,"13200000" Mores Creek
library(dataRetrieval)
start=as.Date("2017-10-01")
end= as.Date("2018-09-30")
USGSsites= c("13185000", "13186000", "13190500", "13192200","13200000","13202000")
#BRB<- readNWISdata(sites= USGSsites, service="iv", startDate=start, endDate=end) #this puts all of them in one giant table w 7 blank columns... not ideal
siteInfo<-readNWISdata(sites= USGSsites, service="site")
### Data Organized by Individual Sites
pCode <- "00060"
Boise_twnSpr <- readNWISuv(siteNumbers = 13185000, parameterCd = pCode, startDate = start, endDate = end)
Boise_twnSpr <- renameNWISColumns(Boise_twnSpr)
SF_featherville <- readNWISuv(siteNumbers = 13186000, parameterCd = pCode, startDate = start, endDate = end)
SF_featherville <- renameNWISColumns(SF_featherville)
Mores<- readNWISuv(siteNumbers=13200000, parameterCd = pCode, startDate = start, endDate = end)
Mores<-renameNWISColumns(Mores)
SF_And<- readNWISuv(siteNumbers = 13190500, parameterCd = pCode, startDate = start, endDate = end)
SF_And <- renameNWISColumns(SF_And)
SF_Arrow<- readNWISuv(siteNumbers = 13192200, parameterCd = pCode, startDate = start, endDate = end)
SF_Arrow <- renameNWISColumns(SF_Arrow)
Boise_LP<- readNWISuv(siteNumbers=13202000, parameterCd = pCode, startDate = start, endDate = end)
Boise_LP<- renameNWISColumns(Boise_LP)
#Missing Data
for ( i in 1:length(ArrowRock)){
if (ArrowRock$Flow_Inst[i] == -999999){ArrowRock$Flow_Inst[i] = NA}
}
for ( i in 1:length(featherville)){
if (featherville$Flow_Inst[i] == -999999){featherville$Flow_Inst[i] = NA}
}
####
feather<- data.frame(featherville)
NF<- data.frame(NFboise)
Anderson<-data.frame(AndersonRanch)
Arrow<- data.frame(ArrowRock)
flows <- merge(feather, NF, by= 'dateTime')
flow <- merge(Anderson, Arrow, by= 'dateTime')
Q1<- merge(flow, flows, by='dateTime')
Q<-subset(Q1, select = c(dateTime, Flow_Inst.x.x, Flow_Inst.y.x, Flow_Inst.x.y, Flow_Inst.y.y))
colnames(Q)<- c("dateTime", "Anderson", "ArrowRock", "Featherville", "NFboise")
ts <- ggplot(data = Q,
aes(dateTime, Anderson)) +
geom_line()
ts
plot(Q$dateTime, Q$NFboise, type="l", col="blue")
View(SF_Arrow)
#Missing Data
for ( i in 1:length(ArrowRock)){
if (SF_Arrow$Flow_Inst[i] == -999999){SF_Arrow$Flow_Inst[i] = NA}
}
for ( i in 1:length(featherville)){
if (SF_featherville$Flow_Inst[i] == -999999){SF_featherville$Flow_Inst[i] = NA}
}
for ( i in 1:length(SF_Arrow)){
if (SF_Arrow$Flow_Inst[i] == -999999){SF_Arrow$Flow_Inst[i] = NA}
}
for ( i in 1:length(SF_featherville)){
if (SF_featherville$Flow_Inst[i] == -999999){SF_featherville$Flow_Inst[i] = NA}
}
feather<- data.frame(SF_featherville)
NF<- data.frame(NFboise)
Anderson<-data.frame(AndersonRanch)
Arrow<- data.frame(ArrowRock)
flows <- merge(feather, NF, by= 'dateTime')
flow <- merge(Anderson, Arrow, by= 'dateTime')
Q1<- merge(flow, flows, by='dateTime')
Q<-subset(Q1, select = c(dateTime, Flow_Inst.x.x, Flow_Inst.y.x, Flow_Inst.x.y, Flow_Inst.y.y))
colnames(Q)<- c("dateTime", "Anderson", "ArrowRock", "Featherville", "NFboise")
SF_featherville<- data.frame(SF_featherville)
NFboise<- data.frame(NFboise)
SF_And<-data.frame(SF_And)
SF_Arrow<- data.frame(SF_Arrow)
LuckyPeak<-data.frame(Boise_LP)
Mores<- data.frame(Mores)
Q1<- merge(feather, NFboise, SF_And, SF_Arrow, LuckyPeak, Mores, by='dateTime')
Q1<- merge(SF_featherville, Boise_twnSpr, SF_And, SF_Arrow, LuckyPeak, Mores, by='dateTime')
Q1<- merge(SF_featherville, Boise_twnSpr, SF_And, SF_Arrow, LuckyPeak, Mores, by='dateTime')
flows <- merge(SF_featherville, Boise_twnSpr, by= 'dateTime')
View(flows)
Q1<- do.call("merge", list(SF_featherville, Boise_twnSpr, SF_And, SF_Arrow, LuckyPeak, Mores), by='dateTime')
list(SF_featherville, Boise_twnSpr, SF_And, SF_Arrow, LuckyPeak, Mores)
library(reshape)
install.packages("reshape")
library(reshape)
library(reshape)
Q1<-merge_all(list(SF_featherville, Boise_twnSpr, SF_And, SF_Arrow, LuckyPeak, Mores), by='dateTime')
View(Boise_LP)
Boise_LP<- readNWISuv(siteNumbers=13202000, parameterCd = pCode, startDate = start, endDate = end)
Boise_LP<- renameNWISColumns(Boise_LP)
Q1<-merge_all(list(SF_featherville, Boise_twnSpr, SF_And, SF_Arrow, Mores), by='dateTime')
Q1<-merge_all(list(SF_And, Boise_twnSpr, SF_Arrow, SF_featherville, Mores), by='dateTime')
dfs<-list(SF_And, Boise_twnSpr, SF_Arrow, SF_featherville, Mores)
Q1<-merge_all(dfs, by='dateTime')
SF_And$dateTime[1]
SF_Arrow$dateTime[1]
Boise_twnSpr$dateTime[1]
SF_featherville$dateTime[1]
Mores$dateTime[1]
install.packages("reshape2")
dfs<-list(SF_And, Boise_twnSpr, SF_Arrow, SF_featherville, Mores)
Q1<-merge_all(dfs, by='dateTime')
library(reshape)
library(reshape2)
dfs<-list(SF_And, Boise_twnSpr, SF_Arrow, SF_featherville, Mores)
Q1<-merge_all(dfs, by='dateTime')
install.packages("tidyverse")
library(tidyverse)
list(SF_And, Boise_twnSpr, SF_Arrow, SF_featherville, Mores) %>% reduce(left_join, by ='dateTime')
Q1<-list(SF_And, Boise_twnSpr, SF_Arrow, SF_featherville, Mores) %>% reduce(left_join, by ='dateTime')
View(Q1)
Q1(head)
head(Q1)
Q1<-list(data.frame(SF_And), data.frame(Boise_twnSpr), data.frame(SF_Arrow), data.frame(SF_featherville), data.frame(Mores)) %>% reduce(merge, by ='dateTime')
Q1<-list(data.frame(SF_And), data.frame(Boise_twnSpr), data.frame(SF_Arrow), data.frame(SF_featherville), data.frame(Mores)) %>% reduce(left_join, by ='dateTime')
head(Q1)
colnames(Q)<- c("dateTime", "Anderson", "Boise_twnSpr", "SF_ArrowRock", "SF_featherville", "Mores")
library(ggplot)
install.packages("ggplot2")
library(ggplot2)
ts <- ggplot(data = Q,
aes(dateTime, Anderson)) +
geom_line()
ts
Q<-subset(Q1, select = c(dateTime, Flow_Inst.x, Flow_Inst.y, Flow_Inst.x.x, Flow_Inst.y.y, Flow_Inst))
colnames(Q)<- c("dateTime", "Anderson", "Boise_twnSpr", "SF_ArrowRock", "SF_featherville", "Mores")
ts <- ggplot(data = Q,
aes(dateTime, Anderson)) +
geom_line()
ts
plot(Q$dateTime, Q$Boise_twnSpr, type="l", col="blue")
lines(Q$dateTime, Q$Anderson,  col="red")
lines(Q$dateTime, Q$SF_ArrowRock)
lines(Q$dateTime, Q$SF_featherville, col="green")
plot(Q$dateTime, Q$Boise_twnSpr, type="l", col="blue")
lines(Q$dateTime, Q$SF_featherville, col="green")
Q1<-list( data.frame(Boise_twnSpr), data.frame(SF_featherville), data.frame(Mores), data.frame(SF_And), data.frame(SF_Arrow)) %>% reduce(left_join, by ='dateTime')
Q<-subset(Q1, select = c(dateTime, Flow_Inst.x, Flow_Inst.y, Flow_Inst.x.x, Flow_Inst.y.y, Flow_Inst))
colnames(Q)<- c("dateTime", "Boise_twnSpr", "SF_featherville", "Mores", "Anderson", "SF_ArrowRock")
library(tidyverse)
Q1<-list( data.frame(Boise_twnSpr), data.frame(SF_featherville), data.frame(Mores), data.frame(SF_And), data.frame(SF_Arrow)) %>% reduce(left_join, by ='dateTime')
Q<-subset(Q1, select = c(dateTime, Flow_Inst.x, Flow_Inst.y, Flow_Inst.x.x, Flow_Inst.y.y, Flow_Inst))
colnames(Q)<- c("dateTime", "Boise_twnSpr", "SF_featherville", "Mores", "Anderson", "SF_ArrowRock")
plot(Q$dateTime, Q$Boise_twnSpr, type="l", col="blue")
lines(Q$dateTime, Q$SF_featherville, col="green")
lines(Q$dateTime, Q$Mores,  col="red")
View(Q)
Boise_twnSpr <- readNWISuv(siteNumbers = 13185000, parameterCd = pCode, startDate = start, endDate = end) %>% renameNWISColumns()
library(dataRetrieval)
Boise_twnSpr <- readNWISuv(siteNumbers = 13185000, parameterCd = pCode, startDate = start, endDate = end) %>% renameNWISColumns()
View(Boise_twnSpr)
Boise_twnSpr <- readNWISuv(siteNumbers = 13185000, parameterCd = pCode, startDate = start, endDate = end) %>% renameNWISColumns() %>% data.frame()
start=as.Date("1998-10-01")
end= as.Date("2018-09-30")
USGSsites= c("13185000", "13186000", "13190500", "13192200","13200000","13202000")
siteInfo<-readNWISdata(sites= USGSsites, service="site")
### Data Organized by Individual Sites
pCode <- "00060"
Boise_twnSpr <- readNWISuv(siteNumbers = 13185000, parameterCd = pCode, startDate = start, endDate = end) %>% renameNWISColumns() %>% data.frame()
type(Boise_twnSpr)
class(Boise_twnSpr)
#---------------
# Download all USGS data from the Upper Boise Basin
# Kendra Kaiser January 9th 2018
#---------------
# HUC codes: 17050111	North and Middle Forks Boise; 17050112	Boise-Mores; 17050113	South Fork Boise - there should be a way to dnld data w these instead of manually finding all the relevant gauges
# siteIDs: "13185000" Boise NR Twin Springs, "13186000" SF Boise NR Featherville, "13190500" SF Boise @ Anderson Ranch,
# "13192200" SF Boise @ Neal Bridge nr Arrowrock,"13200000" Mores Creek
library(dataRetrieval)
library(tidyverse)
start=as.Date("1998-10-01")
end= as.Date("2018-09-30")
USGSsites= c("13185000", "13186000", "13190500", "13192200","13200000","13202000")
siteInfo<-readNWISdata(sites= USGSsites, service="site")
### Data Organized by Individual Sites
pCode <- "00060"
Boise_twnSpr <- readNWISuv(siteNumbers = 13185000, parameterCd = pCode, startDate = start, endDate = end) %>% renameNWISColumns() %>% data.frame
SF_featherville <- readNWISuv(siteNumbers = 13186000, parameterCd = pCode, startDate = start, endDate = end) %>% renameNWISColumns() %>% data.frame
Mores<- readNWISuv(siteNumbers=13200000, parameterCd = pCode, startDate = start, endDate = end) %>% renameNWISColumns() %>% data.frame
SF_And<- readNWISuv(siteNumbers = 13190500, parameterCd = pCode, startDate = start, endDate = end) %>% renameNWISColumns() %>% data.frame
SF_Arrow<- readNWISuv(siteNumbers = 13192200, parameterCd = pCode, startDate = start, endDate = end) %>% renameNWISColumns() %>% data.frame
#Missing Data
for ( i in 1:length(SF_Arrow)){
if (SF_Arrow$Flow_Inst[i] == -999999){SF_Arrow$Flow_Inst[i] = NA}
}
for ( i in 1:length(SF_featherville)){
if (SF_featherville$Flow_Inst[i] == -999999){SF_featherville$Flow_Inst[i] = NA}
}
# Merge and subset dataframes
Q1<-list(Boise_twnSpr, SF_featherville, Mores, SF_And, SF_Arrow) %>% reduce(left_join, by ='dateTime')
Q<-subset(Q1, select = c(dateTime, Flow_Inst.x, Flow_Inst.y, Flow_Inst.x.x, Flow_Inst.y.y, Flow_Inst))
colnames(Q)<- c("dateTime", "Boise_twnSpr", "SF_featherville", "Mores", "Anderson", "SF_ArrowRock")
plot(Q$dateTime, Q$Boise_twnSpr, type="l", col="blue")
lines(Q$dateTime, Q$SF_featherville, col="green")
lines(Q$dateTime, Q$Mores,  col="red")
#save it
write.csv(Q, file="BRB_Q_wy98-18.csv")
plot(Q$dateTime, Q$Boise_twnSpr, type="l", col="blue")
lines(Q$dateTime, Q$SF_featherville, col="green")
is.na(Q$Boise_twnSpr)
which(is.na(Q$Boise_twnSpr))
